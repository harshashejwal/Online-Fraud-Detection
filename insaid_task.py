# -*- coding: utf-8 -*-
"""INSAID_TASK.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13vTe5iRVsGupDfs4AsIOO-Cpe0gmfbYs
"""

import pandas as pd
import numpy as np

#uploading data from computer to dataframe
data=pd.read_csv("/content/drive/MyDrive/Fraud.csv")

"""It is very highly imbalanced dataset so for that we can also used SMOTE Technique to resolve this issue

"""

data

#check the null value
print(data.isnull().sum())

#Exploring trasaction type
data.type.value_counts()

type=data["type"].value_counts()

transaction=type.index 
quantity=type.values

import plotly.express as px
figure = px.pie(data,values=quantity, names=transaction, hole=0.5, title="Distor of Transaction Type")
figure.show()

#checking corelation of dataset feature
correlation=data.corr()

correlation["isFraud"].sort_values(ascending=False)

data["type"] = data["type"].map({"CASH_OUT":1,"PAYMENT":2,"CASH_IN":3,"TRANSFER":4,"DEBIT":5})
print(data.head)

data["isFraud"]=data["isFraud"].map({0:"no fraud", 1:"fraud"})

data.head()

x=np.array(data[["type","amount","oldbalanceOrg","newbalanceOrig"]])

y=np.array(data[["isFraud"]])

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.10,random_state=42)

"""**modeling and Evaluation using Decision tree**"""

#model train

xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.10,random_state=42)
from sklearn.tree import DecisionTreeClassifier
model =  DecisionTreeClassifier()
model.fit(xtrain, ytrain)



print(model.score(xtest,ytest))

from sklearn.model_selection import train_test_split
xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.10,random_state=42)

predictions = model.predict(xtest)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

"""**Describe your fraud detection model in elaboration**
Here we have get accuracy of TPR,FPR  better than Xgboost by using decision tree.
"""

cm = confusion_matrix(ytest, predictions, labels=model.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_)
disp.plot()
plt.show()

from sklearn.metrics import classification_report
print(classification_report(ytest,predictions))

"""**modeling and Evaluation using XGBOOST **"""

from xgboost.sklearn import XGBClassifier
md_xg=XGBClassifier()
md_xg.fit(xtrain,ytrain)

y_prd_train = md_xg.predict(xtrain)
y_prd_test = md_xg.predict(xtest)

from sklearn.metrics import accuracy_score
print(accuracy_score(ytrain,y_prd_train))
print(accuracy_score(ytest,y_prd_test))

cm = confusion_matrix(ytest, y_prd_test, labels=md_xg.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=md_xg.classes_)
disp.plot()
plt.show()

from sklearn.metrics import classification_report
print(classification_report(ytest,y_prd_test))

"""**We are getting more accuracy,f1score, in decision tree so we are selecting that**

**How did you select variables to be included in the model**
By Removing unique columns ,checking correlation of features.

** What are the key factors that predict fraudulent customer?**

Key features for analysing the fraudulent customers by understanding the dataset ,I have get are as follows."type","amount","oldbalanceOrg","newbalanceOrig"
"""